# 「대형 언어 모델(LLM)을 활용한 고고학 정보화 연구 – 발굴조사보고서의 메타데이터 자동 추출 파이프라인 개념 검증」 PoC (스냅샷)

본 저장소는 『헤리티지: 역사와 과학』 제58권 제3호(2025년 9월 30일) 게재 논문 「대형 언어 모델(LLM)을 활용한 고고학 정보화 연구 – 발굴조사보고서의 메타데이터 자동 추출 파이프라인 개념 검증」에서 구현한 PoC 코드의 “스냅샷”입니다. 학술적·기술적 투명성을 위해 소스코드를 공개합니다. 다만 이 저장소는 연구 시점의 기록 보존 목적이며, 추가 개발이나 제3자의 기여(Contribution)는 받지 않습니다.

- [디지털 부록 바로가기](https://poc.heripo.com)
- [논문 요약 영상 시청](https://youtu.be/iyAXYahDiT0)
- [PoC 시연 영상 시청](https://youtu.be/PCKKLPBP78w)
- [논문 다운로드 페이지 바로가기]()
- [리서치 레이더(heripo) 구독하러 가기](https://heripo.com/research-radar/subscribe)

## 스냅샷 공지 및 유의사항(반드시 읽어주세요)
- 본 코드는 연구의 아이디어와 가능성 검증에 초점을 둔 PoC로, 프로덕션 수준의 안정성·보안·코드 품질을 보장하지 않습니다.
- 현재 저장소는 유지보수하지 않으며, 이슈나 PR은 받지 않습니다. 연구 기록의 공개가 목적입니다.
- 코드 일부(특히 화면/프론트엔드)는 LLM 보조 도구를 활용해 빠르게 작성했으며, 정교한 디자인 패턴을 따르지 않습니다. 페이지 단일 파일에 로직이 몰려 있는 등 실험적 구조가 존재합니다.
  - 저는 시니어 소프트웨어 엔지니어로, 웹 프론트엔드를 전문적으로 다루고 있습니다만,
  - 본 저장소의 코드 품질이 저의 프론트엔드 엔지니어링 전문성을 대변하지는 않습니다.
- TypeScript/Next.js 선택은 연구자의 익숙함과 실험 편의성 때문입니다. 실전 적용 시에는 상황에 더 적합한 언어/프레임워크를 선택하세요.
- 본 코드는 아래 “보고서 3종”에 맞추어 실험적으로 구성되었으며, 다른 형식의 보고서에는 최적화되어 있지 않습니다. 다만 OCR이 필요하지 않은 대부분의 보고서에서는 대체로 동작합니다.
  - 백제역사문화연구원, 2025, 『부여 화지산 백제과원 및 둘레길 조성사업부지내 유적』.
  - 일영문화유산연구원, 2025, 『제주 항파두리 항몽유적 내성지(7차)』.
  - 겨레문화유산연구원, 2025, 『공주 석장리 구석기 유적(14차)』.
- OCR은 지원하지 않습니다. 최신 보고서도 텍스트가 아웃라인 처리된 경우가 있어 OCR이 필요한 사례가 생길 수 있으니 참고하세요.
- 반드시 로컬 환경에서만 테스트하세요. 서버에 배포하거나 인터넷 공개 환경에서 실행하지 마세요.
  - 보안: 종속성 업데이트/취약점으로 인해 예기치 않은 보안 이슈가 발생할 수 있습니다.
  - 비용: OpenAI API 호출 비용이 클 수 있습니다(실행 시 수만원대 과금 가능). 로컬에서 제한적으로, 테스트 수준으로만 실행하세요.

## 오픈소스 공개 목적 및 책임 한계
- 이 저장소 공개의 1차 목적은 연구의 투명성과 학술적 기록 공유입니다. 코드를 공개했다고 해서 실행을 권장하거나 요구하는 것은 아닙니다.
- 다만 코드를 공개하는 순간 누구나 실행이 가능해지므로, 최소한의 실행 안내를 제공합니다.
- 이 코드를 실행함으로써 발생할 수 있는 보안·비용·데이터 보호·법적 이슈 등 모든 리스크와 책임은 전적으로 실행자 본인에게 있습니다. 저장소 소유자는 어떠한 책임도 지지 않습니다.
- 소프트웨어 및 코딩에 대한 기본 지식과 경험이 있는 사용자만 제한적으로 실행하기를 권장합니다.

본 연구를 기반으로 한 최신 기술과 고도화된 기능은 heripo 플랫폼의 별도 저장소에서 개발 중입니다. 서비스 수준으로 완성되는 시점에 핵심 로직을 오픈소스로 전환할 계획입니다.

## 앞으로의 오픈소스 공개 계획

앞으로도 핵심 기술들을 학계의 ‘공동 자산’으로 만들어가겠습니다.

- 리서치 레이더 코어 로직 공개: PoC보다 더 발전된 형태인 ‘리서치 레이더’의 핵심 파이프라인 역시 2025년 10월 중 추가로 공개할 예정입니다.
- 후속 R&D 성과 공개: 더 나아가 현재 개발 중인 heripo 플랫폼의 핵심 로직 또한, 서비스가 가능한 수준으로 완성도가 높아지면 오픈소스 프로젝트로 전환할 것을 약속드립니다.

저는 이 오픈소스 프로젝트의 오너이자 메인테이너로서 핵심 기술을 발전시키는 학술적·기술적 기여를 계속해 나갈 것입니다. 그리고 이 기술이 세상에 더 널리 쓰일 수 있도록 이를 기반으로 한 heripo 플랫폼을 직접 개발하고 안정적으로 운영하며 생태계의 성장을 이끌겠습니다.

---

## 연구 배경 및 논문 요약

본 저장소가 다루는 PoC는 고고학 분야의 비정형 텍스트(발굴조사보고서)를 자동으로 구조화하여 데이터베이스화하려는 연구의 실증 결과물입니다. 아래는 논문의 핵심 내용을 요약한 것으로, 저장소의 코드와 사용법을 맥락 속에서 이해하는 데 도움을 줍니다.

### 1) 서론: 문제의식과 목표
- 고고학은 방대한 발굴조사보고서가 주로 비정형 텍스트로 존재하여 체계적 활용과 확산에 어려움이 큽니다.
- 본 연구는 LLM을 이용해 보고서 본문에서 유적·유구·유물의 핵심 메타데이터를 자동 추출·구조화하는 파이프라인의 실현 가능성을 검증합니다.
- 목표는 기술 소개를 넘어, 데이터 기반 분석을 고고학 연구의 일상적 수단으로 정착시키는 프레임워크를 제안하는 데 있습니다(‘정보고고학’의 지향).

### 2) 기존 정보화 논의와 구조적 한계
- (흐름) 2000년대 이후 논의가 있었으나, 단편적 제안에 그치거나 지속 동력 부재로 단절됨.
  - 2000년대 초: 학술적 DB 모델 제안, 실무 중심 전자문서화 제안 등장.
  - 2010년대: 국가 정책 차원에서 기록자원 통합·아카이브 구축의 필요성 명시(원문 열람 수준에 머무름).
  - 2010년대 후반~: 해외 디지털 아카이브 분석, 시맨틱 웹·온톨로지·텍스트 마이닝 등 이론적 제안은 다수이나 실용 적용은 제한적.
- (구조적 제약) 고고학 데이터 특수성(방대·다양·동적), 기술·학문 간 괴리, 전통적 정보화 방식의 경직성(표준 선행 필요), 제도적 제약(예산·인력·조직 부족) 등이 근본 한계로 작용.

### 3) LLM: 새로운 패러다임
- 기술적 차별점
  - 문맥 이해: 트랜스포머/자기 주의로 긴 문맥의 의미 관계를 파악.
  - 유연한 적응: 사전학습 + 미세조정으로 전문 용어·서술 구조에 대응.
- 고고학 적용의 강점
  - 보고서는 반복 항목이 많은 ‘반정형 텍스트’ 성격을 지니므로, LLM이 별도의 복잡한 전처리 없이도 속성·맥락을 추출해 구조화하기에 적합.
- 한계와 보완 전략
  - 한계: 환각, 최신성 부족, 멱등성 결여.
  - 보완: RAG(외부 지식 연동), 프롬프트 엔지니어링, 전문가 검토를 결합한 하이브리드 접근.

### 4) PoC 아키텍처(이 저장소 구현과의 매핑)
본 PoC는 “PDF 분석 → 이미지-캡션 연결 → 메타데이터 추출/구조화 → SQLite 저장 → RAG 기반 질의응답”의 5모듈로 구성됩니다. 저장소 코드와의 주요 매핑은 다음과 같습니다.
- PDF 처리(파이썬): PDF에서 텍스트/이미지 및 위치 좌표 추출.
  - src/modules/pdf-process/pdf-extractor.py, requirements.txt, index.ts
- 캡션 매칭(규칙/LLM): 이미지와 캡션을 위치/맥락 기반으로 연결.
  - src/modules/caption-extract-mapper/*
- 메타데이터 자동 추출 및 구조화(LLM): 보고서 본문에서 유적/트렌치/유구/유물 정보를 스키마에 맞게 JSON으로 생성.
  - src/modules/make-data/*, src/libs/open-ai.ts, src/utils/extract-pure-json.ts
- 데이터베이스(SQLite): 정제한 레코드를 RDB에 저장.
  - src/modules/insert-database/index.ts → data/excavation.db
- 웹 인터페이스 및 AI 서비스(RAG): 결과 확인과 질의응답.
  - src/app/*, src/app/api/chat/route.ts, src/libs/glossarySearchEngine.ts

처리 전략상, 유적 개괄은 20p 단위, 유구·유물은 2p 단위로 텍스트를 분할하여 LLM에 투입합니다(보고서 간 서술 편차를 완화하기 위함).

### 5) 실험 결과 요약
- 구조화 정확도
  - 유적 개괄·트렌치 정보는 높은 정확도. 유구–유물 연계에서 일부 오류 발생 → 누적 병합/재시도 로직으로 보완 여지 확인.
  - 이미지–개체 매칭은 일부 누락이 있어 추가 개선 필요.
- 비용 효율성
  - 보고서 1건당 약 2만 원 수준의 기준선 도출(상용 LLM API 사용 기준). 대규모 적용 시 비용 저감 전략(오픈소스 LLM 등)이 필수.
- AI 서비스 기능
  - 구조화 데이터 + 사전 임베딩(RAG) 결합으로 “유물 비교/개념 설명/교차 유적 질의” 등 고차원 Q&A 가능성 확인.
  - 채팅 기반 UI는 숙련도에 따른 편차가 커, 도메인 특화 시각적 인터페이스의 필요성 확인.
- 확장성
  - 모듈식 파이프라인으로 OCR, 고급 시각화 등 기능 추가가 용이.
  - 이미지 기반 PDF 처리를 위한 OCR 도입은 실무 확장에 필수.

### 6) 결론 및 향후 과제
- 플랫폼 개발: 본 개념 모델을 바탕으로 2025년 하반기 공개를 목표로 웹 기반 프로토타입을 개발 중(사용자 피드백을 통해 고도화 예정).
- ‘정보고고학’ 제안: 자동 구조화와 지능형 탐색을 축으로 연구 방법론의 질적 전환을 지향.
- 제도적 기반: 도면/3D/좌표 등 원천 디지털 자료의 표준 제출·공개와 국가 차원의 통합 관리 필요.
- 확장 가능성: 미술사·건축사·민속학 등 문화유산 전반으로의 확장이 가능한 범용 모델.

위 요약은 아래의 “소스코드 개요와 처리 흐름” 및 “빠른 시작” 섹션과 함께 읽으면, PoC의 기술적 세부와 연구적 의의를 함께 파악하는 데 도움이 됩니다.

---

## 빠른 시작(Quick Start)
아래 절차는 “로컬 단발성 테스트”를 위한 안내입니다. 배포/운영 목적 사용은 금지합니다.

1) 필수 소프트웨어
- Node.js: LTS 버전 권장(버전 종속성 크지 않음)
  - 설치 가이드(GUI 중심): [Node.js 설치 가이드](./docs/nodejs-installation.md)
- Python: 시스템에 설치 필요
  - 설치 가이드(GUI 중심): [Python 설치 가이드](./docs/python-installation.md)

2) 저장소 클론 및 의존성 설치
- 저장소 클론 후 프로젝트 루트에서 실행:
  - `npm install`
  - 설치 시 자동 실행되는 preinstall 스크립트가 다음을 수행합니다:
    - 데이터/임베딩 파일 다운로드: `scripts/download-glossary-embeddings.js` → `data/glossary-embeddings.json` 저장(대용량 파일)
    - Python 가상환경 생성 및 의존성 설치: `scripts/setup-python-env.js` → `.venv` 생성 후 `src/modules/pdf-process/requirements.txt` 설치

3) 환경 변수 설정(중요)
- 루트의 `.env.local.example`를 복사해 `.env.local` 파일을 생성하고 OpenAI API 키를 입력하세요.
  - 발급 가이드: [OpenAI API 키 발급 가이드](./docs/openai-api-key.md)
  - 예시:
    - `OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxx`
  - 중요: API 키 관리와 사용량/비용 관리는 실행자 본인의 책임이며, 저장소 소유자는 책임지지 않습니다.
- 민감 정보는 절대 커밋/공개하지 마세요. `.env.local`은 `.gitignore`에 포함되어 있습니다.

4) 빌드 및 실행(개발 서버 대신 빌드 실행 권장)
- 빌드: `npm run build:production`
- 실행: `npm start`
- 브라우저에서 접속: http://localhost:3000

5) 실행 시 주의사항(반복 강조)
- 로컬에서 제한적으로만 테스트하세요. 서버 업로드/배포 금지.
- OpenAI API 과금에 주의하세요. 대용량 PDF 처리 시 토큰 사용량이 급증합니다.

---

## 소스코드 개요와 처리 흐름
PoC는 “PDF 업로드 → PDF 텍스트/이미지 추출(파이썬) → 이미지-캡션 매핑(규칙/LLM) → 본문 분석 및 구조화(LLM) → SQLite 저장 → 대화형 질의응답(LLM+사전)”의 파이프라인으로 동작합니다.

1) 프론트엔드(UI)
- 파일 업로드/처리 페이지: `src/app/page.tsx`
  - PDF 업로드(최대 500MB), 페이지 유형(PageType: 단면/양면), 실제 첫 페이지(realFirstPage) 입력
  - 업로드 후 정형화 API 호출(`/api/report/standardize`), 처리 상태 폴링 지원

2) 업로드 API
- `POST /api/report/upload` → 업로드 파일을 프로젝트 루트의 `uploads/`에 저장하고 `reportId` 반환
  - 구현: `src/app/api/report/upload/route.ts`

3) 정형화(Standardize) API
- `POST /api/report/standardize` → 업로드된 PDF를 처리하여 구조화 수행
  - 구현: `src/app/api/report/standardize/route.ts`
  - 파라미터: `reportId`, `pageType`(1/2), `realFirstPage`(offset)
  - 내부에서 `standardizeReport()` 호출: `src/app/api/report/standardize/standardize-report.ts`

4) PDF 처리(파이썬 호출)
- Node에서 파이썬 스크립트 실행: `src/modules/pdf-process/index.ts`
  - `.venv/bin/python`(Windows는 `.venv\Scripts\python.exe`)로 `src/modules/pdf-process/pdf-extractor.py` 호출
  - 결과(JSON): 텍스트/이미지 좌표, 페이지 정보 등
- 파이썬 의존성: `src/modules/pdf-process/requirements.txt`

5) 이미지-캡션 매핑
- 규칙 기반(기본): `src/modules/caption-extract-mapper/captionExtractMapperWithRule.ts`
- LLM 기반(옵션): `src/modules/caption-extract-mapper/captionExtractMapperWithLLM.ts`
- 공통 엔트리: `src/modules/caption-extract-mapper/index.ts`

6) 본문 분석 및 데이터 구성(LLM)
- 메인 엔트리: `src/modules/make-data/index.ts`
  - 유적 개요 추출: `makeExcavatedSiteData.ts` → 목차 기반으로 “조사 내용” 시작/다음 장 추정, 이미지 캡션 근거로 이미지 연결, 누적 병합 로직 포함
  - 트렌치/유구/유물 추출: `makeTrenchFeatureArtifactData.ts` → 2페이지 단위로 분할 분석하며 누적 병합 및 재시도 로직 포함
- 공통 LLM 호출 유틸: `src/libs/open-ai.ts` (`OPENAI_API_KEY` 필요)
- JSON 파싱 유틸: `src/utils/extract-pure-json.ts`(LLM 출력의 코드블록 제거 및 오류 시 raw 보존)

7) 데이터 저장(SQLite)
- DB 삽입: `src/modules/insert-database/index.ts`
  - 파일: `data/excavation.db` (없으면 생성)
  - 중복/누락 ID 정제, 참조 무결성 보조 매핑 수행 후 `excavated_sites`, `trenches`, `features`, `artifacts`에 삽입

8) 결과 파일(디버깅/기록)
- `public/pdf-result/`에 중간/최종 산출물 JSON 저장
  - 예: `${reportId}.json`, `${reportId}-db-*.json`

9) 질의응답(LLM + 사전)
- API: `POST /api/chat` → DB 내용을 바탕으로 답변, 필요 시 한국 고고학 사전(임베딩 검색) 보조
  - 구현: `src/app/api/chat/route.ts`
  - 사전 검색: `src/libs/glossarySearchEngine.ts`(임베딩: `data/glossary-embeddings.json`)

---

## 환경 변수(.env.local)
- `OPENAI_API_KEY`: OpenAI API 키(필수)
  - 발급 가이드: [OpenAI API 키 발급 가이드](./docs/openai-api-key.md)
  - 중요: API 키 관리와 사용량/비용 관리는 실행자 본인의 책임이며, 저장소 소유자는 책임지지 않습니다.
- `.env.local.example`를 참고하여 `.env.local` 파일을 생성하세요. 민감 정보는 공개 저장소에 커밋하지 마세요.

## 데이터/파일 경로
- 업로드된 PDF: `uploads/` (임시 저장)
- 디버그/결과 JSON: `public/pdf-result/`
- SQLite DB: `data/excavation.db`
- 사전 임베딩: `data/glossary-embeddings.json`(preinstall 시 자동 다운로드)

## 실행 비용/보안 관련 주의사항(중복 강조)
- 과금: LLM 호출량이 많아질수록 비용이 급증합니다. 테스트 용도로만 제한적으로 실행하세요.
- 보안: 종속성 이슈로 인한 취약 가능성이 있습니다. 외부 서비스 배포 금지, 로컬 환경에서만 실행하세요.

## 의존성 스냅샷 및 호환성
- 본 저장소에는 논문 투고 시점의 종속성 스냅샷이 포함되어 있습니다:
  - `package.snapshot.json`, `package-lock.snapshot.json`
- 현재 `package.json`의 버전은 최소한의 패치 업데이트가 반영될 수 있으며, 스냅샷은 재현성 참고용으로 제공됩니다. 환경에 따라 설치/실행 결과가 달라질 수 있습니다.

## 알려진 제약/한계
- 이미지 기반(스캔) PDF 중 텍스트 추출이 불가한 경우는 지원하지 않습니다.
- 보고서 형식 편차가 크면 추출 품질이 저하될 수 있습니다.
- LLM 응답은 확률적이며, 일부 필드 추출이 누락되거나 오탐이 있을 수 있습니다.
- 프론트엔드 구조는 실험적이며, 정교한 설계/패턴을 따르지 않습니다.

## 라이선스
- MIT License(저장소 루트의 LICENSE 참조)
- 단, 본 저장소의 목적은 학술적 투명성 및 연구 기록 공개입니다. 실전/운영 환경 적용은 권장하지 않습니다.
